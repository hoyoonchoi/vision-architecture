{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "lFODtDePQF37"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "from torchsummary import summary\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#global variable for training\n",
        "#you just use the following hyper-parameters\n",
        "BATCH_SIZE = 100\n",
        "NUM_EPOCHS = 2\n",
        "LEARNING_RATE = 0.01\n",
        "CRITERION= nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "SRTQiC6YQfZ5"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CIFAR10 Dataset\n",
        "train_dataset = dsets.CIFAR10(root='./data',\n",
        "                            train=True,\n",
        "                            transform=transforms.ToTensor(),\n",
        "                            download=True)\n",
        "test_dataset = dsets.CIFAR10(root='./data',\n",
        "                           train=False,\n",
        "                           transform=transforms.ToTensor())\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=BATCH_SIZE,\n",
        "                                           shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=BATCH_SIZE,\n",
        "                                          shuffle=False)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DagptOG1QxhW",
        "outputId": "1ff8f627-f80d-4508-dbd2-19ae18b28e59"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:03<00:00, 49006574.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset.classes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ITXmhJRoRjrd",
        "outputId": "b907e1b1-d66f-4b8e-8f63-bc85b871eb96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['airplane',\n",
              " 'automobile',\n",
              " 'bird',\n",
              " 'cat',\n",
              " 'deer',\n",
              " 'dog',\n",
              " 'frog',\n",
              " 'horse',\n",
              " 'ship',\n",
              " 'truck']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset.class_to_idx\n",
        "index= 4\n",
        "print(train_dataset.targets[index])\n",
        "print(train_dataset.data[index].shape)\n",
        "plt.imshow(train_dataset.data[index])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        },
        "id": "OrnHuzuDRoY_",
        "outputId": "3ef1c2b1-6e3f-4f68-af1b-59092333e60b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "(32, 32, 3)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7acab8b7d780>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def fit(model,train_loader):\n",
        "  # 1 epoch training\n",
        "  model.train()\n",
        "  device = next(model.parameters()).device.index #GPU인지 CPU인지 추론 하는 거 같은거\n",
        "  optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=0.9)\n",
        "  losses= []\n",
        "  for i, data in enumerate(train_loader):\n",
        "    image = data[0].type(torch.FloatTensor).cuda(device)\n",
        "    label = data[1].type(torch.LongTensor).cuda(device)\n",
        "\n",
        "    pred_label = model(image)\n",
        "    loss = CRITERION(pred_label, label)\n",
        "    losses.append(loss.item())\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  avg_loss = sum(losses)/len(losses)\n",
        "  return avg_loss\n"
      ],
      "metadata": {
        "id": "bvidO5RSS3bW"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def eval(model, test_loader):\n",
        "  model.eval()\n",
        "  device = next(model.parameters()).device.index\n",
        "  pred_labels = []\n",
        "  real_labels = []\n",
        "\n",
        "  for i, data in enumerate(test_loader):\n",
        "    image = data[0].type(torch.FloatTensor).cuda(device)\n",
        "    label = data[1].type(torch.LongTensor).cuda(device)\n",
        "    real_labels += list(label.cpu().detach().numpy())\n",
        "    #detach는 gpu위에 이는 pytotch를 numpy로 바꾸기 위한 것임\n",
        "\n",
        "\n",
        "    pred_label = model(image)\n",
        "    pred_label = list(pred_label.cpu().detach().numpy())\n",
        "    pred_labels += pred_label\n",
        "\n",
        "  real_labels= np.array(real_labels)\n",
        "  pred_labels = np.array(pred_labels)\n",
        "  pred_labels = pred_labels.argmax(axis=1)\n",
        "  #argmax 하는 과정은 10개의 클래스의 확률을 output으로\n",
        "  #내는 과정을 1개의 최대 값을 배출 하는 과정을 나는 내는 것임\n",
        "\n",
        "  acc = sum(real_labels == pred_labels)/len(real_labels)*100\n",
        "\n",
        "  return acc"
      ],
      "metadata": {
        "id": "sX6zKqxgUyBE"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task1: Compare between simple MLP and simple CNN"
      ],
      "metadata": {
        "id": "d8C-R_UjYTy-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "MLP"
      ],
      "metadata": {
        "id": "oH-zuwoCYciz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SImpleMLP(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(SImpleMLP, self).__init__()\n",
        "    #FULLY-connceted layer)\n",
        "    self.fc1_1 = nn.Linear(3*32*32, 8*28*28)\n",
        "    self.act1_1 = nn.ReLU()\n",
        "    self.fc1_2 = nn.Linear(8*28*28, 8*24*24)\n",
        "    self.act1_2 = nn.ReLU()\n",
        "    self.pool1 = nn.MaxPool2d(2)\n",
        "\n",
        "    self.fc2_1 = nn.Linear(8*12*12, 16*8*8)\n",
        "    self.act2_1 = nn.ReLU()\n",
        "    self.fc2_2 = nn.Linear(16*8*8, 16*4*4)\n",
        "    self.act2_2 = nn.ReLU()\n",
        "    self.pool2 = nn.MaxPool2d(2)\n",
        "\n",
        "    self.out = nn.Linear(16*2*2, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = x.view(-1, 3*32*32)\n",
        "\n",
        "    x = self.act1_1(self.fc1_1(x))\n",
        "    x = self.act1_2(self.fc1_2(x))\n",
        "    x = x.view(-1,8,24,24)\n",
        "    x= self.pool1(x)\n",
        "    x = x.view(-1, 8*12*12)\n",
        "\n",
        "    x = self.act2_1(self.fc2_1(x))\n",
        "    x = self.act2_2(self.fc2_2(x))\n",
        "    x = x.view(-1,16,4,4)\n",
        "    x= self.pool2(x)\n",
        "    x = x.view(-1, 16*2*2)\n",
        "\n",
        "    out = self.out(x)\n",
        "    return out"
      ],
      "metadata": {
        "id": "qxBRlPjsYb-R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mlp_model = SImpleMLP().cuda()\n",
        "train_loss1 = []\n",
        "test_accuracy1 = []\n",
        "for epoch in tqdm(range(NUM_EPOCHS)):\n",
        "  #시간들을 bar 형태로 보여주는 것\n",
        "  train_loss1.append(fit(mlp_model, train_loader))\n",
        "  test_accuracy1.append(eval(mlp_model, test_loader))\n",
        "\n",
        "summary(mlp_model, input_size= (3, 32, 32))\n",
        "#layer별로 파라미터를 보여 주는 것"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gOd0Qf0FYStU",
        "outputId": "143fa4c6-b3da-445f-8c53-17a4a33d21f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:20<00:00, 10.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Linear-1                 [-1, 6272]      19,273,856\n",
            "              ReLU-2                 [-1, 6272]               0\n",
            "            Linear-3                 [-1, 4608]      28,905,984\n",
            "              ReLU-4                 [-1, 4608]               0\n",
            "         MaxPool2d-5            [-1, 8, 12, 12]               0\n",
            "            Linear-6                 [-1, 1024]       1,180,672\n",
            "              ReLU-7                 [-1, 1024]               0\n",
            "            Linear-8                  [-1, 256]         262,400\n",
            "              ReLU-9                  [-1, 256]               0\n",
            "        MaxPool2d-10             [-1, 16, 2, 2]               0\n",
            "           Linear-11                   [-1, 10]             650\n",
            "================================================================\n",
            "Total params: 49,623,562\n",
            "Trainable params: 49,623,562\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 0.19\n",
            "Params size (MB): 189.30\n",
            "Estimated Total Size (MB): 189.51\n",
            "----------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss1, test_accuracy1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6O1XPPDgbqer",
        "outputId": "8cf8c412-e1b4-4ece-d0e5-0439d37b9cb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([1.9416428534984589, 1.6798721625804902], [37.24, 42.22])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CNN"
      ],
      "metadata": {
        "id": "0gu42XwOcdvH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TAsk 2:VGG"
      ],
      "metadata": {
        "id": "nIpMqmEXcexE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "VGG"
      ],
      "metadata": {
        "id": "Phu06njWcgnb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.utils.model_zoo as model_zoo\n",
        "\n",
        "model_urls = {\n",
        "    \"vgg11\": \"https://download.pytorch.org/models/vgg11-bbd30ac9.pth\",\n",
        "    \"vgg13\": \"https://download.pytorch.org/models/vgg13-c768596a.pth\",\n",
        "    \"vgg16\": \"https://download.pytorch.org/models/vgg16-397923af.pth\",\n",
        "    \"vgg19\": \"https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\",\n",
        "    \"vgg11_bn\": \"https://download.pytorch.org/models/vgg11_bn-600\",\n",
        "    \"vgg13_bn\": \"https://download.pytorch.org/models/vgg13_bn-abd245e\",\n",
        "    \"vgg16_bn\": \"https://download.pytorch.org/models/vgg16_bn-6c6\",\n",
        "    \"vgg19_bn\": \"https://download.pytorch.org/models/vgg19_bn-c794\",\n",
        "    }\n"
      ],
      "metadata": {
        "id": "S-S0KmwabxeB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VGG(nn.Module):\n",
        "\n",
        "  def __init__(self, features, num_classes=1000, init_weights=True):\n",
        "    super(VGG, self).__init__()\n",
        "    self.features = features\n",
        "    #feature extractor: convolutional filter의 뭉치.\n",
        "    #feature extractor : convolutional filter의 뭉치. nn.conv2d, nn.batchnorm, .. nn.linear)\n",
        "    self.classifier = nn.Sequential(\n",
        "        nn.Linear(512 * 7 * 7, 4096),\n",
        "        nn.ReLU(True),\n",
        "        nn.Dropout(),\n",
        "        nn.Linear(4096, 4096),\n",
        "        nn.ReLU(True),\n",
        "        nn.Dropout(),\n",
        "        nn.Linear(4096, num_classes),\n",
        "    )   #sequentail을 만들면 한번에 써줄 수 있음 !!\n",
        "    if init_weights:\n",
        "      self._initialize_weights()\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.features(x) #batch size X 512 X 7 x/7\n",
        "    x = x.view(x.size(0), -1) #x.size(0) = batch size X (512*7*&7)\n",
        "    #view는 텐서의 크기를 변경하는데 사용되는 것임\n",
        "    #첫 번째 차원은 그대로 두고 나머지 차원들을 하나로 평탄화하는 작업\n",
        "\n",
        "    x = self.classifier(x)\n",
        "    return x\n",
        "\n",
        "  def _initialize_weights(self):\n",
        "    for m in self.modules():\n",
        "      #여기서 말하는 모듈은 feature를 뜻함. nn.~~~\n",
        "      if isinstance(m, nn.Conv2d):\n",
        "        nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "        #kalming initialization\n",
        "        if m.bias is not None:\n",
        "          nn.init.constant_(m.bias, 0)\n",
        "      elif isinstance(m, nn.BatchNorm2d):\n",
        "        nn.init.constant_(m.weight, 1)\n",
        "        nn.init.constant_(m.bias, 0)\n",
        "      elif isinstance(m, nn.Linear):\n",
        "        nn.init.normal_(m.weight, 0, 0.01)\n",
        "        nn.init.constant_(m.bias, 0)\n",
        "\n",
        "def make_layers(cfg, batch_norm=False):\n",
        "         # config : ditionary 기반으로 encoding 하는 것\n",
        "         #network 정보들을 저장해놓은 것을 통상적으로 부름\n",
        "    layers= []\n",
        "    in_channels = 3\n",
        "    for v in cfg:\n",
        "      if v == 'M':\n",
        "        layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
        "      else:\n",
        "        conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n",
        "        #batch_norm이 있으면 batchnorm을 추가하고\n",
        "        #아니면 그냥 conv와 ReLU 함수를 진행 함.\n",
        "        if batch_norm:\n",
        "          layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n",
        "        else:\n",
        "          layers += [conv2d, nn.ReLU(inplace=True)]\n",
        "        in_channels = v\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "cfg = {\n",
        "    'A': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512,512, 'M'],\n",
        "    #output channel 수 , M은 maxpool을 의미함\n",
        "    'B': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
        "    'C': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512,512, 'M', 512, 512, 512, 'M'],\n",
        "    'D': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n",
        "    }\n",
        "\n",
        "def vgg11(pretrained=False, **kwargs):\n",
        "    if pretrained:\n",
        "      kwargs['init_weights'] = False\n",
        "    model = VGG(make_layers(cfg['A']), **kwargs)\n",
        "    if pretrained:\n",
        "      model.load_state_dict(model_zoo.load_url(model_urls['vgg11']))\n",
        "    return model\n",
        "\n",
        "def vgg11_bn(pretrained=False, **kwargs):\n",
        "    if pretrained:\n",
        "      kwargs['init_weights'] = False\n",
        "    model = VGG(make_layers(cfg['A'], batch_norm=True), **kwargs)\n",
        "    if pretrained:\n",
        "      model.load_state_dict(model_zoo.load_url(model_urls['vgg11_bn']))\n",
        "    return model\n",
        "\n",
        "\n",
        "def vgg13(pretrained=False, **kwargs):\n",
        "    if pretrained:\n",
        "      kwargs['init_weights'] = False\n",
        "    model = VGG(make_layers(cfg['B']), **kwargs)\n",
        "    if pretrained:\n",
        "       model.load_state_dict(model_zoo.load_url(model_urls['vgg13']))\n",
        "    return model\n",
        "\n",
        "def vgg13_bn(pretrained=False, **kwargs):\n",
        "    if pretrained:\n",
        "      kwargs['init_weights'] = False\n",
        "    model = VGG(make_layers(cfg['B'], batch_norm=True), **kwargs)\n",
        "    if pretrained:\n",
        "      model.load_state_dict(model_zoo.load_url(model_urls['vgg13_bn']))\n",
        "    return model\n",
        "\n",
        "def vgg16(pretrained=False, **kwargs):\n",
        "    '''VGG 16-layer model (configuration \"D\")\n",
        "      Args:\n",
        "          pretrained (bool): if True, returns a model pre-trained on ImageNet'''\n",
        "    if pretrained:\n",
        "      kwargs['init_weights'] = False\n",
        "    model = VGG(make_layers(cfg['D']), **kwargs)\n",
        "    if pretrained:\n",
        "      model.load_state_dict(model_zoo.load_url(model_urls['vgg16']))\n",
        "    return model\n",
        "\n",
        "def vgg16_bn(pretrained=False, **kwargs):\n",
        "    '''VGG 16-layer model (configuration \"D\")\n",
        "      Args:\n",
        "          pretrained (bool): if True, returns a model pre-trained on ImageNet'''\n",
        "    if pretrained:\n",
        "      kwargs['init_weights'] = False\n",
        "    model = VGG(make_layers(cfg['D'], batch_norm=True), **kwargs)\n",
        "    if pretrained:\n",
        "      model.load_state_dict(model_zoo.load_url(model_urls['vgg16_bn']))\n",
        "    return model\n",
        "\n",
        "def vgg19(pretrained=False, **kwargs):\n",
        "    '''VGG 19-layer model (configuration \"E\")\n",
        "      Args:\n",
        "          pretrained (bool): if True, returns a model pre-trained on ImageNet'''\n",
        "    if pretrained:\n",
        "      kwargs['init_weights'] = False\n",
        "    model = VGG(make_layers(cfg['E']), **kwargs)\n",
        "    if pretrained:\n",
        "      model.load_state_dict(model_zoo.load_url(model_urls['vgg19']))\n",
        "    return model\n",
        "\n",
        "def vgg19_bn(pretrained=False, **kwargs):\n",
        "    '''VGG 19-layer model (configuration 'E')\n",
        "      Args:\n",
        "          pretrained (bool): if True, returns a model pre-trained on ImageNet'''\n",
        "    if pretrained:\n",
        "     kwargs['init_weights'] = False\n",
        "    model = VGG(make_layers(cfg['E'], batch_norm=True), **kwargs)\n",
        "    if pretrained:\n",
        "      model.load_state_dict(model_zoo.load_url(model_urls['vgg19_bn']))\n",
        "    return model\n",
        "\n"
      ],
      "metadata": {
        "id": "QpxJ98QSckYf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vgg_model = vgg11_bn(num_classes=10).cuda()\n",
        "train_loss3 = []\n",
        "test_accuracy3 = []\n",
        "for epoch in tqdm(range(NUM_EPOCHS)):\n",
        "  #시간들을 bar 형태로 보여주는 것\n",
        "  train_loss3.append(fit(mlp_model, train_loader))\n",
        "  test_accuracy3.append(eval(mlp_model, test_loader))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXaV_Smpq9xg",
        "outputId": "42227408-4cff-4ba3-a352-f65faeaa92ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:21<00:00, 10.74s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3PYLgEqq9u6",
        "outputId": "badd6862-bf51-43b9-cd9b-5b484c514359"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Jul 20 10:30:06 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   73C    P0              32W /  70W |   1529MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 3 : ResNet"
      ],
      "metadata": {
        "id": "OdPFqx1QtA3f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "ResNet in PyTorch.\n",
        "For Pre-activaition ResNet, see 'preact_resnet.py'.\n",
        "Referenc:\n",
        "[1] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun\n",
        "    Deep Residual Learning for Image Recognition. arXiv:1512.03385\n",
        "'''\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "  expansion = 1\n",
        "\n",
        "  def __init__(self, in_planes, planes, stride=1): #inplane = input channels\n",
        "                                                   #plane = output channels\n",
        "    super(BasicBlock, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "    self.bn1 = nn.BatchNorm2d(planes)\n",
        "    self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "    self.bn2 = nn.BatchNorm2d(planes)\n",
        "      #일반적으로는 convolutional 넘어간 것에 x를 붙임.\n",
        "      #그러나 shortcut을 해야할 때가 있음. stride가 1이 아니거나 input값이 다른 경우\n",
        "    self.shortcut = nn.Sequential()\n",
        "    if stride != 1 or in_planes != self.expansion*planes:\n",
        "      self.shortcut = nn.Sequential(\n",
        "          nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
        "          nn.BatchNorm2d(self.expansion*planes)\n",
        "      )\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = F.relu(self.bn1(self.conv1(x)))\n",
        "    out = self.bn2(self.conv2(out))\n",
        "    out += self.shortcut(x)\n",
        "    out = F.relu(out)\n",
        "    return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "  expansion = 4\n",
        "#convolutional 층을 3개를 만들고 batchnorm까지 진행한 후에 +selfcut을 넣고 relu를 진행하는 형태임.\n",
        "  def __init__(self, in_planes, planes, stride=1):\n",
        "    super(Bottleneck, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
        "    self.bn1 = nn.BatchNorm2d(planes)\n",
        "    self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "\n",
        "    self.bn2 - nn.BatchNorm2d(planes)\n",
        "    self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=False)\n",
        "    self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
        "    self.shortcut = nn.Sequential()\n",
        "    if stride != 1 or in_planes != self.expansion*planes:\n",
        "      self.shortcut = nn.Sequential(\n",
        "          nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
        "          nn.BatchNorm2d(self.expansion*planes)\n",
        "      )\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = F.relu(self.bn1(self.conv1(x)))\n",
        "    out = F.relu(self.bn2(self.conv2(out)))\n",
        "    out = self.bn3(self.conv3(out))\n",
        "    out += self.shortcut(x)\n",
        "    out = F.relu(out)\n",
        "    return out\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "  def __init__(self, block, num_blocks, num_classes=10):\n",
        "    super(ResNet, self).__init__()\n",
        "    self.in_planes = 64\n",
        "\n",
        "    self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "    self.bn1 = nn.BatchNorm2d(64)\n",
        "    self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "    self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "    self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "    self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "    self.linear = nn.Linear(512*block.expansion, num_classes)\n",
        "\n",
        "  def _make_layer(self,block,planes, num_blocks, stride):\n",
        "    #stride를 제외한 나머지 블락은 1로 채우는 것임,\n",
        "    strides = [stride] + [1]*(num_blocks-1)\n",
        "    layers= []\n",
        "    for stride in strides:\n",
        "        layers.append(block(self.in_planes, planes, stride))\n",
        "        self.in_planes = planes * block.expansion\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = F.relu(self.bn1(self.conv1(x)))\n",
        "    out = self.layer1(out)\n",
        "    out = self.layer2(out)\n",
        "    out = self.layer3(out)\n",
        "    out = self.layer4(out)\n",
        "    out = F.avg_pool2d(out, 4) #batch_size x 512 x 1 x 1\n",
        "    out = out.view(out.size(0), -1) #flatten 하는 과정\n",
        "    out = self.linear(out)\n",
        "    return out\n",
        "\n",
        "def ResNet18():\n",
        "  return ResNet(BasicBlock, [2,2,2,2])\n",
        "\n",
        "def ResNet34():\n",
        "    return ResNet(BasicBlock, [3,4,6,3])\n",
        "\n",
        "def ResNet50(): #50 부터는 bottleneck을 주로 사용함\n",
        "                   #block layer는 논문에 구현 되어 있는 수치임\n",
        "    return ResNet(Bottleneck, [3,4,6,3])\n",
        "\n",
        "\n",
        "def ResNet101():\n",
        "    return ResNet(Bottleneck, [3,4,23,3])\n",
        "\n",
        "def Resnet152():\n",
        "    return ResNet(Bottleneck, [3,8,36,3])\n",
        "\n",
        "def test():\n",
        "    net = ResNet19()\n",
        "    y= net(torch.randn(1,3,32,32))\n",
        "    print(y.size())\n",
        "\n"
      ],
      "metadata": {
        "id": "XmCqMicrsI4D"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_model = ResNet18().cuda()\n",
        "train_loss4 = []\n",
        "test_accuracy4 = []\n",
        "for epoch in tqdm(range(NUM_EPOCHS)):\n",
        "  #시간들을 bar 형태로 보여주는 것\n",
        "  train_loss4.append(fit(resnet_model, train_loader))\n",
        "  test_accuracy4.append(eval(resnet_model, test_loader))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HqHJJUvuwcdp",
        "outputId": "c1e3789d-1fad-4616-b95d-bb6203e87174"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [01:33<00:00, 46.95s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_loss4)\n",
        "print(test_accuracy4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uuUZUxvg1GHC",
        "outputId": "3b8ad8e1-3b6a-42c2-b5ba-d4ba29f07d3e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.274281534433365, 0.732148706138134]\n",
            "[62.4, 69.57]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "AdrYgul11OKW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 4 : MobileNet"
      ],
      "metadata": {
        "id": "2hJtv0zu1Qnj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# 이전 가져오기를 새 가져오기로 바꿉니다.\n",
        "# from torchvision.models.utils import load_state_dict_from_url\n",
        "load_state_dict_from_url = torch.hub.load_state_dict_from_url"
      ],
      "metadata": {
        "id": "JWUF2tYs1i2E"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvBNReLU(nn.Module):\n",
        "  def __init__(self, in_planes, out_planes, kernel_size=3, stride=1, groups=1, bn_aff= True):\n",
        "    padding = (kernel_size -1) // 2\n",
        "    super(ConvBNReLU, self).__init__()\n",
        "    self.conv= nn.Conv2d(in_planes, out_planes, kernel_size, stride, padding, groups=groups, bias=False)\n",
        "    self.bn = nn.BatchNorm2d(out_planes,affine= bn_aff)\n",
        "    self.relu= nn.ReLU6(inplace=True)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x= self.conv(x)\n",
        "    x=self.bn(x)\n",
        "    x= self.relu(x)\n",
        "    return x\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "VKRvJ1Hi2gQC"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#pointwise - BN-depthwise -BN=relu6 - pointwise - bn\n",
        "\n",
        "class invertedResiudal(nn.Module):\n",
        "  def __init__(self, inp, oup, stride, expand_ratio, shortcut, bn_aff):\n",
        "    super(invertedResiudal, self).__init__()\n",
        "    self.shortcut = shortcut\n",
        "    self.bn_aff = bn_aff\n",
        "    self.stride= stride\n",
        "    assert stride in [1,2]\n",
        "\n",
        "    hidden_dim = int(round(inp * expand_ratio))\n",
        "    self.use_res_connect = self.stride == 1 and inp == oup\n",
        "\n",
        "    layers = []\n",
        "    if expand_ratio != 1:\n",
        "      #pw:\n",
        "      layers.append(ConvBNReLU(inp, hidden_dim, kernel_size=1, bn_aff=self.bn_aff))\n",
        "    layers.extend([\n",
        "        #dw : featur map 의  out channels 는 hodden_dim\n",
        "        ConvBNReLU(hidden_dim, hidden_dim, stride=stride, groups=hidden_dim, bn_aff=bn_aff),\n",
        "        #pw-linear squeeze #kernal size -stride -padding\n",
        "        nn.Conv2d(hidden_dim, oup, kernel_size=1),\n",
        "        nn.BatchNorm2d(oup, affine=self.bn_aff)\n",
        "    ])\n",
        "    self.conv = nn.Sequential(*layers)\n",
        "\n",
        "  def forward(self, x):\n",
        "    if self.use_res_connect:\n",
        "      if self.shortcut:\n",
        "        return x + self.conv(x)\n",
        "      else:\n",
        "        return self.conv(x)\n",
        "    else:\n",
        "        return self.conv(x)"
      ],
      "metadata": {
        "id": "O6brq_Fb3QUH"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_urls= {\n",
        "    'mobilenet_v2': 'https://download.pytorch.org/models/mobilenet_v2-b0353104.pth',\n",
        "}\n",
        "def _make_divisible(x, divisible_by=8):\n",
        "  import numpy as np\n",
        "  return int(np.ceil(x*1. / divisible_by)* divisible_by)\n",
        "\n",
        "class MobileNetV2(nn.Module):\n",
        "  def __init__(self, num_classes=1000, width_mult=1.0, inverted_residual_setting=None, round_nearest=8\n",
        "              ,block=None, shortcut = True, bn_aff=True):\n",
        "    super(MobileNetV2, self).__init__()\n",
        "\n",
        "    if block is None:\n",
        "      block = invertedResiudal\n",
        "    input_channel = 32\n",
        "    last_channel = 1280\n",
        "    self.bn_aff = bn_aff\n",
        "    self.shortcut = shortcut\n",
        "\n",
        "    if inverted_residual_setting is None:\n",
        "      inverted_residual_setting = [\n",
        "          # t(expansion rate), c(outputchanel), n(blocks),s(stride)\n",
        "          [1, 16, 1, 1],\n",
        "          [6, 24, 2, 2], #stride 2가 2개 나오는게 아니라 마지막에  1개만 나옴\n",
        "                         #[16-96-24] -[16-96-24] 과정이두번 나옴 #laber intensive\n",
        "           [6, 32, 3, 2],\n",
        "          [6, 64, 4, 2],\n",
        "\n",
        "      ]\n",
        "\n",
        "    if len(inverted_residual_setting) == 0 or len(inverted_residual_setting)!=4:\n",
        "      raise ValueError('inverted_residual_setting should be non-empty or a 4-element list')\n",
        "\n",
        "    # building first layer\n",
        "    input_channel = _make_divisible(input_channel * width_mult, round_nearest)\n",
        "    self.last_channel = _make_divisible(last_channel * max(1.0, width_mult), round_nearest)\n",
        "    features = [ConvBNReLU(3, input_channel, stride=2, bn_aff=self.bn_aff)]\n",
        "\n",
        "    #building inverted residual blocks\n",
        "    for t,c,n,s in inverted_residual_setting:\n",
        "      output_channel = _make_divisible(c * width_mult, round_nearest)\n",
        "      for i in range(n):\n",
        "          stride = s if i == 0 else 1\n",
        "          features.append(block(input_channel,output_channel,stride, expand_ratio=t,\n",
        "                                shortcut = self.shortcut, bn_aff=self.bn_aff))\n",
        "          input_channel = output_channel\n",
        "\n",
        "    #building test several layers\n",
        "    features.append(ConvBNReLU(input_channel, self.last_channel, kernel_size=1, bn_aff=self.bn_aff))\n",
        "\n",
        "   #make it nn.Sequential\n",
        "    self.features = nn.Sequential(*features)\n",
        "\n",
        "   #building classifier\n",
        "    self.classifier = nn.Sequential(\n",
        "        nn.Dropout(),\n",
        "        nn.Linear(self.last_channel, num_classes),\n",
        "    )\n",
        "\n",
        "   # weight initialization\n",
        "    for m in self.modules():\n",
        "      if isinstance(m, nn.Conv2d):\n",
        "        nn.init.kaiming_normal_(m.weight, mode='fan_out', )\n",
        "        if m.bias is not None:\n",
        "          nn.init.zeros_(m.bias)\n",
        "      elif isinstance(m, nn.BatchNorm2d):\n",
        "        nn.init.ones_(m.weight)\n",
        "        nn.init.zeros_(m.bias)\n",
        "      elif isinstance(m, nn.Linear):\n",
        "        nn.init.normal_(m.weight, 0, 0.01)\n",
        "        nn.init.zeros_(m.bias)\n",
        "\n",
        "  def _forward_impl(self, x):\n",
        "\n",
        "      x=self.features(x)\n",
        "      x=nn.functional.adaptive_avg_pool2d(x, 1).reshape(x.shape[0],-1)\n",
        "      x=self.classifier(x)\n",
        "      return x\n",
        "\n",
        "  def forward(self, x):\n",
        "      return self._forward_impl(x)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "chmalDwX-ZnB"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mobilenet_v2(pretrained=False, progress=True, **kwargs):\n",
        "\n",
        "  model = MobileNetV2(**kwargs)\n",
        "  if pretrained:\n",
        "    state_dict = load_state_dict_from_url(model_urls['mobilenet_v2'],\n",
        "                                          progress=progress)\n",
        "    model.load_state_dict(state_dict)\n",
        "  return model"
      ],
      "metadata": {
        "id": "ErPnjxpeEXaH"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_bn_model = mobilenet_v2(num_classes=10).cuda()\n",
        "train_loss5=[]\n",
        "test_accuracy5=[]\n",
        "for epoch in tqdm(range(NUM_EPOCHS)):\n",
        "  #시간들을 bar 형태로 보여주는 것\n",
        "  train_loss5.append(fit(resnet_bn_model, train_loader))\n",
        "  test_accuracy5.append(eval(resnet_bn_model, test_loader))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uv06yh7KEkoA",
        "outputId": "eafde40a-0317-41e4-db04-f81e885e2c94"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:31<00:00, 15.60s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print (train_loss5)\n",
        "print(test_accuracy5)"
      ],
      "metadata": {
        "id": "QzwhoGTOJJyD",
        "outputId": "ae4360b8-e3a0-48af-8020-0021607fd92a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.701685840845108, 1.339791757941246]\n",
            "[46.410000000000004, 56.18]\n"
          ]
        }
      ]
    }
  ]
}